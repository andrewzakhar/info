{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "import os\n",
    "import scipy.interpolate\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import max_error\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import dateparser\n",
    "import statistics\n",
    "\n",
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\viwell\n",
      "C:\\projects\\viwell\n"
     ]
    }
   ],
   "source": [
    "# Настройка папок\n",
    "# Рабочей папкой считаем папку выше \\Скрипт\n",
    "cCurrentPath_ = os.path.split(os.path.abspath(''))[0]\n",
    "print(cCurrentPath_)\n",
    "# cWorkFolder = r'F:\\Work'\n",
    "cWorkFolder = cCurrentPath_\n",
    "print(cWorkFolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор источника низкочастотных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если grad = False, то данные подгружаются из ШТР\n",
    "grad = True\n",
    "BSI = False #True # Используем высокочастотные сырые данные из БСИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список месторождений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oilfields = ['Вынгаяхинское'] \n",
    "#, 'Суторминское', 'Вынгаяхинское', 'Восточно-Пякутинское'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные по скважине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dintake_ = 100 # Диаметр приемной сетки насоса (пока что одинаковый для всех)\n",
    "KsepGasSep_ = 0.7 # Коэффициент сепарации\n",
    "#TKsep_ = 89 # Температура сепарации\n",
    "#Tintake_ = 20 # Температура на приеме\n",
    "PVT_corr_ = 0 # PVT корреляция для записи в строку PVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tube_and_pump_characteristics(well_name, oilfield_):\n",
    "    os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера\\ГРАД'))\n",
    "    \n",
    "    df_pump = pd.read_excel(\n",
    "        'БОМД. Оборудование актуальных паспортов_Филиал Муравленковскнефть ОАО Газпромнефть-ННГ_04.03.2020 14-57-02.xlsx', \n",
    "                            sheet_name='Основной_лист', header=3).dropna(axis=1, how = 'all')\n",
    "    Nominal_production_ = df_pump.loc[(df_pump['№ скважины'] == well_name) & (\n",
    "                    df_pump['Месторождение'] == oilfield_)]['Подача комплекта, м3'].values[0]\n",
    "    df_pump = df_pump[['№ скважины', 'Месторождение', 'Глубина спуска','0_Типоразмер_Секции_ЭЦН', '1_Типоразмер_Секции_ЭЦН',\n",
    "                  '1_Количество_ступеней', '2_Количество_ступеней', '3_Количество_ступеней', \n",
    "                  '4_Количество_ступеней', '5_Количество_ступеней', '6_Количество_ступеней', '7_Количество_ступеней',\n",
    "                    '8_Количество_ступеней', '9_Количество_ступеней']]\n",
    "    df_pump = df_pump.loc[(df_pump['№ скважины'] == well_name) & (df_pump['Месторождение'] == oilfield_)].dropna(axis=1)\n",
    "    Hpump_ = int(df_pump['Глубина спуска'])\n",
    "    NumStage_ = int(np.sum(df_pump.iloc[0][4:]))\n",
    "    ESP_name_ = str(df_pump['1_Типоразмер_Секции_ЭЦН'].values[0])\n",
    "    \n",
    "    # Получаем ID насоса по имени, если имени нет, нужно брать по напору\n",
    "    \n",
    "    df_ESP_id = pd.read_csv('ESP_base_unifloc.csv', encoding=\"windows 1251\", header=0, sep=';')\n",
    "    try:\n",
    "        ESP_id_ = df_ESP_id.loc[df_ESP_id['Модель'] == ESP_name_]['ID'].iloc[0] \n",
    "    except:\n",
    "        ESP_id_ = ESP_id_by_rate(Nominal_production_)\n",
    "\n",
    "    \n",
    "    ESP_name_unifloc_ = ESP_name(str(ESP_id_))\n",
    "           \n",
    "    #df_tube = pd.read_excel('ТР все скв Мессояха (есть НКТ).xlsx', header=2).dropna(axis=1, how='all')\n",
    "    #df_tube = df_tube[['Скважина', 'Диаметр экспл.колонны', 'Диаметр НКТ']].dropna()\n",
    "    #try: \n",
    "    #    Dcas_ = df_tube.loc[df_tube['Скважина'] == well_name+'G']['Диаметр экспл.колонны'].iloc[0]\n",
    "    #    Dtub_ = df_tube.loc[df_tube['Скважина'] == well_name+'G']['Диаметр НКТ'].iloc[0]\n",
    "    #except:\n",
    "    #    Dcas_ = df_tube.loc[df_tube['Скважина'] == well_name+'G2']['Диаметр экспл.колонны'].iloc[0]\n",
    "    #    Dtub_ = df_tube.loc[df_tube['Скважина'] == well_name+'G2']['Диаметр НКТ'].iloc[0]\n",
    "    #    \n",
    "    #\n",
    "    \n",
    "    Dcas_ = 178 #Типичный размер ЭК для данного мр-я\n",
    "    \n",
    "    # Значения диаметра НКТ от глубины\n",
    "    if BSI == False:\n",
    "        os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера') +\n",
    "                r'\\ГРАД' + '\\\\' + oilfield_ + r'\\Ствол\\НКТ')\n",
    "        for file in os.listdir(os.getcwd()):\n",
    "            if well_name in file:\n",
    "                filename = file\n",
    "        d_tube_df = pd.read_excel(filename, header=1)\n",
    "        d_tube_df['Глубина окончания секции'] = d_tube_df['длина,м'][0]\n",
    "        for i in range(0, len(d_tube_df)):\n",
    "            d_tube_df['Глубина окончания секции'].loc[i] = np.sum(d_tube_df['длина,м'][:i+1])    \n",
    "        d_tube_df['диаметр(мм)/сортамент'] = d_tube_df['диаметр(мм)/сортамент'].str.slice(0,2)\n",
    "        d_tube_df['диаметр(мм)/сортамент'].astype(int)\n",
    "    else:\n",
    "        d_tube_df = pd.DataFrame()\n",
    "    \n",
    "    data = {'Hpump_' : Hpump_, 'NumStage_' : NumStage_, 'Dcas_' : Dcas_, 'Dtub_' : d_tube_df, 'ESP_id_' : ESP_id_,\n",
    "           'ESP_name_' : ESP_name_, 'ESP_name_unifloc_' : ESP_name_unifloc_}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inclinometry(well_name):\n",
    "    \n",
    "    os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера') +\n",
    "                 r'\\ГРАД' + '\\\\' + oilfield_ + r'\\Ствол\\Инклинометрия')\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        if well_name in file:\n",
    "            filename = file\n",
    "    df = pd.read_excel(filename, header=0).dropna(axis=1, how = 'all')\n",
    "    df['Inc'].astype(float)\n",
    "    df[['Inc']] = 90 - df[['Inc']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_data(low, well_name):\n",
    "# Функция считывает данные за 3 часа или 8 часов в зависимости от флага low. \n",
    "\n",
    "    if low:    \n",
    "        if grad and BSI:\n",
    "            path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                                  'ГРАД', oilfield_, r'Осреднение\\High freq')\n",
    "        else:\n",
    "            os.chdir(r'F:\\Work\\Данные для виртуальной расходометрии\\Ноябрьск'\n",
    "                         r'\\информация для виртуального расходомера\\ШТР' + '\\\\' + oilfield_)\n",
    "        \n",
    "        for file in os.listdir(os.getcwd()):\n",
    "            if well_name in file:\n",
    "                filename = file\n",
    "        res = get_data_both(low, well_name, filename)\n",
    "            \n",
    "    else:\n",
    "        if BSI == False:\n",
    "            path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                                  'ГРАД', oilfield_, r'Осреднение\\High freq')\n",
    "        elif grad and BSI:\n",
    "            os.chdir(r'F:\\Work\\Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера'\n",
    "                         r'\\БСИ' + '\\\\' + oilfield_)\n",
    "        for file in os.listdir(os.getcwd()):\n",
    "            if well_name in file:\n",
    "                filename = file\n",
    "        res = get_data_both(low, well_name, filename)\n",
    "       \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_both(low, well_name, filename):\n",
    "# Считываение осредненных данных (3 часа или сутки)\n",
    "\n",
    "    #if low and grad:\n",
    "    if low and grad:\n",
    "        df = pd.read_csv(filename, encoding=\"utf-8-sig\", sep=',', index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        #df['Дебит газа (ТМ)'].interpolate(limit_direction='both', inplace=True)\n",
    "        df['Газовый фактор (рассчитанный)'] = df['Дебит газа (ТМ)'] / df['Дебит нефти (ТМ)']\n",
    "        df['Газожидкостной фактор (рассчитанный)'] = df['Дебит газа (ТМ)'] / df['Дебит жидкости (ТМ)']\n",
    "        df['Обводненность (ТМ)'].interpolate(limit_direction='both', inplace=True)\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    elif low == False and grad and BSI:\n",
    "        df = pd.read_excel(filename)\n",
    "        df.set_index('Дата, Время', inplace=True)\n",
    "        df.dropna(subset = ['акт.P,кВт'], inplace=True)\n",
    "        \n",
    "        df.rename(columns={'F, Гц' : 'Частота вращения (ТМ)', 'Tдвиг, °C' : 'Температура двигателя ЭЦН (ТМ)', \n",
    "                           'акт.P,кВт' : 'Активная мощность (ТМ)', 'P, ат.' : 'Давление на входе ЭЦН (ТМ)'},  inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        if low:\n",
    "        \n",
    "            df = pd.read_excel(filename, header=2, parse_dates=['Unnamed: 0'], date_parser=dateparser.parse)\n",
    "            df.rename(columns={'Unnamed: 0' : 'Дата', 'ГФР(ТМ)': 'Газожидкостной фактор (рассчитанный)',\n",
    "                              'Обв ТМ' : 'Обводненность (ТМ)', 'Рэцн ТМ' : 'Давление на входе ЭЦН (ТМ)',\n",
    "                              'Тдвиг ТМ' : 'Температура двигателя ЭЦН (ТМ)'}, inplace=True)\n",
    "            df['Обводненность (ТМ)'] = (1 - df['Qн*'] / df['Qж ТМ']) * 100 # перевод в %\n",
    "            df['Обводненность (ТМ)'].interpolate(limit_direction='both', inplace=True)\n",
    "            df.set_index('Дата', inplace=True)\n",
    "            df = df[['Газожидкостной фактор (рассчитанный)', 'Обводненность (ТМ)', 'Давление на входе ЭЦН (ТМ)',\n",
    "                    'Температура двигателя ЭЦН (ТМ)']]\n",
    "            \n",
    "            os.chdir(r'F:\\Work\\Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера'\n",
    "                r'\\ГРАД' + '\\\\' + oilfield_ + r'\\Осреднение\\High freq')\n",
    "            \n",
    "            for file in os.listdir(os.getcwd()):\n",
    "                if well_name in file:\n",
    "                    filename = file\n",
    "                \n",
    "            df_grad = pd.read_csv(filename, encoding=\"utf-8-sig\", sep=',', index_col=0)\n",
    "            df_grad.index = pd.to_datetime(df_grad.index)\n",
    "            \n",
    "            if well_name == '6013':\n",
    "                df_grad.drop(columns = ['Давление на входе ЭЦН (ТМ)', 'Дебит газа (ТМ)',\n",
    "                                           'Дебит нефти (ТМ)', 'Обводненность (ТМ)'], inplace=True)\n",
    "            if well_name == '3026':\n",
    "                df_grad.drop(columns = ['Дебит нефти (ТМ)', 'Обводненность (ТМ)'], inplace=True)\n",
    "                \n",
    "            \n",
    "            if 'Давление на входе ЭЦН (ТМ)' in df_grad.columns :\n",
    "                df = df[['Газожидкостной фактор (рассчитанный)', 'Обводненность (ТМ)']]   \n",
    "    \n",
    "            df = pd.concat([df_grad, df], axis=1).reindex(df_grad.index)\n",
    "            df.dropna(how='all', inplace=True)\n",
    "        elif grad == True:\n",
    "            \n",
    "            df = pd.read_csv(filename, encoding=\"utf-8-sig\", sep=',', index_col=0)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            \n",
    "            df['Газовый фактор (рассчитанный)'] = df['Дебит газа (ТМ)'] / df['Дебит нефти (ТМ)']\n",
    "            df['Газожидкостной фактор (рассчитанный)'] = df['Дебит газа (ТМ)'] / df['Дебит жидкости (ТМ)']\n",
    "            df['Обводненность (ТМ)'].interpolate(limit_direction='both', inplace=True)\n",
    "        else:\n",
    "            df = pd.read_csv(filename, encoding=\"utf-8-sig\", sep=',', index_col=0)\n",
    "            df.index = pd.to_datetime(df.index)            \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_ml(df_calc, df_data):\n",
    "    # возвращает подготовленные данные \n",
    "    df = pd.concat([df_calc, df_data.drop(columns=['Давление на входе ЭЦН (ТМ)', 'Температура двигателя ЭЦН (ТМ)', \n",
    "                                                       'Давление линейное (ТМ)'])], axis=1).reindex()\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vsp(oilfield, well_name):\n",
    "    # Чтение данных о ВСП (внутрисменные простои) скважин\n",
    "    path = (r'F:\\Work\\Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера\\ВСП')\n",
    "    os.chdir(path)\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        if oilfield in file:\n",
    "            filename = file\n",
    "    df = pd.read_csv(filename, encoding = 'windows 1251', sep=';')\n",
    "    df.drop(columns=['Скв_оис', 'Состояние', 'Источник данных'], inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    items = []\n",
    "    for item in df['Скв'].values:\n",
    "        if '_' in str(item):\n",
    "            item = int(item[:-2])\n",
    "        items.append(item)            \n",
    "    df['Скв'] = items\n",
    "    df = df.loc[df['Скв'] == int(well_name)]\n",
    "    df['ДатаСтарта'] = pd.to_datetime(df['ДатаСтарта'])\n",
    "    df['Дата_Окончания'] = pd.to_datetime(df['Дата_Окончания'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_validation(N, df_res, active_power_1H, f_esp_1H, *args):\n",
    " # Производим расчеты с выбросом некоторых дней с целью контроля ошибки!     \n",
    "    \n",
    "\n",
    "    df_res['K degradation'].iloc[-1] = df_res['K degradation'].iloc[-2]\n",
    "    \n",
    "    each_N_day = df_res.iloc[::N] # Данные за каждый N-й день \n",
    "    if N > 1:\n",
    "        #ДФ с днями, на которых проверяем работу алгоритма (выкидывали каждый N-й день)   \n",
    "        validation_days = df_res.drop(index=each_N_day.index) \n",
    "    else:\n",
    "    #Для проверки последнего замера\n",
    "        validation_days = df_res.iloc[-1:] \n",
    "        each_N_day.drop(index=validation_days.index, inplace=True)\n",
    "        \n",
    "    #resampled_k_deg = each_N_day[['K degradation']].resample('1H')\n",
    "\n",
    "    \n",
    "    if grad and BSI == False:\n",
    "        resampled_k_deg = df_res[['K degradation']].resample('1H')\n",
    "        interpolated_k_deg_1H = resampled_k_deg.interpolate('index')\n",
    "        tKsep_1H = args[0]\n",
    "        wc_1h = args[1]\n",
    "        rp_1H = args[2]\n",
    "        pksep_atma_1H = args[3]\n",
    "        p_lin_1H = args[4]\n",
    "        #resampled_f_esp = each_N_day[['F ESP']].resample('1H').interpolate()# Чтобы частота менялась плавнее внутри суток\n",
    "        #resampled_temp = df_res['Temperature on the surface'].resample('1H').interpolate()\n",
    "        \n",
    "        # На случай, если нет высокочастотной обводненности\n",
    "        #resampled_fw = each_N_day['Fw'].resample('1H').fillna(method='ffill') #Интерполируем обводненность внутри суток\n",
    "        \n",
    "        #resampled_tempKsep = df_res['Температура двигателя ЭЦН (ТМ)'].resample('1H').interpolate()\n",
    "        #resampled_p_lin = df_res['Давление линейное (ТМ)'].resample('1H').interpolate()\n",
    "        interpolated_rp = rp_1H.interpolate()\n",
    "        \n",
    "        return (pd.concat([active_power_1H, f_esp_1H, interpolated_k_deg_1H, tKsep_1H, wc_1h, p_lin_1H, interpolated_rp, \n",
    "                           pksep_atma_1H], axis=1).reindex(), validation_days)\n",
    "    elif grad and BSI:\n",
    "        resampled_k_deg = df_res[['K degradation']].resample('60S')\n",
    "        interpolated_k_deg_1H = resampled_k_deg.interpolate('index')\n",
    "        tKsep_1H = args[0]\n",
    "        pksep_atma_1H = args[1]\n",
    "        \n",
    "        return (pd.concat([active_power_1H, f_esp_1H, interpolated_k_deg_1H, tKsep_1H, \n",
    "                           pksep_atma_1H], axis=1).reindex(), validation_days)\n",
    "    else:\n",
    "        p_lin_1H = args[0]\n",
    "        resampled_k_deg = df_res[['K degradation']].resample('1H')\n",
    "        interpolated_k_deg_1H = resampled_k_deg.interpolate('index')\n",
    "        resampled_tempKsep = df_res['Температура двигателя ЭЦН (ТМ)'].resample('1H').interpolate()\n",
    "        resmpled_pksep_atma = df_res['Давление на входе ЭЦН (ТМ)'].resample('1H').interpolate()\n",
    "        resampled_fw = df_res['Fw'].resample('1H').fillna(method='ffill')\n",
    "        resampled_rp = df_res['Газожидкостной фактор (рассчитанный)'].resample('1H').interpolate()\n",
    "        return (pd.concat([active_power_1H, f_esp_1H, interpolated_k_deg_1H, resampled_tempKsep, resampled_fw, p_lin_1H, \n",
    "                           resampled_rp, resmpled_pksep_atma], axis=1).reindex(), validation_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_power_from_production_table(NumStage_, Freq_, ESP_id_, mu_):\n",
    "    # Для создания табличной функции дебита от мощности. \n",
    "\n",
    "    production = [5, 10]\n",
    "    power = [ESP_power_W(production[0], NumStage_, Freq_, ESP_id_, mu_)/1000, \n",
    "             ESP_power_W(production[-1], NumStage_, Freq_, ESP_id_, mu_)/1000] \n",
    "    i = 1\n",
    "    while power[i]  != power[i-1] and production[-1] < 1000: #production[-1] < np.floor(Mean_prod_ * 1.2):\n",
    "        production.append(production[-1] + 5)\n",
    "        power.append(ESP_power_W(production[-1], NumStage_, Freq_, ESP_id_, mu_)/1000)\n",
    "        i += 1\n",
    "    if len(power) > 2:\n",
    "        del power[-1]\n",
    "        del production[-1]\n",
    "    \n",
    "    diff = np.gradient(power, production)\n",
    "    df = pd.DataFrame(columns = ['Production', 'Power', 'Derivative'])\n",
    "    df['Production'] = production\n",
    "    df['Power'] = power\n",
    "    df['Derivative'] = diff\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_prediction(low, df, First_liq_point_,\n",
    "                         NumStage_, Freq_start_, ESP_id_, mu_, passport_power_table, Fw_mean_, well_name):\n",
    "    # Предсказание через напорно-расходную хар-ку\n",
    "    q_predicted_array = [] # Массив предсказанных дебитов в условиях насоса\n",
    "    q_liq_surface = [] # Массив предсказанных дебитов в поверхностных условиях\n",
    "    counter_off_bounds = 0 # Счетчик точек, не попавших на паспортную хар-ку\n",
    "    mu_array = [] # Массив вязкостей\n",
    "    max_dQ_array = [] # Массив максимальных допустимых изменений дебита с учетом напорной хар-ки на текущем шаге\n",
    "    \n",
    "  \n",
    "    \n",
    "    for i in range(len(df)):       \n",
    "        \n",
    "        ajusted_flag = False # Указывает, варьировалась ли вязкость, если true, то нужно перестраивать напорно-расходную\n",
    "\n",
    "        if i != 0:\n",
    "            mu_temp = mu_ # Параметр для варьирования вязкости\n",
    "            Freq_ = df['F ESP'].iloc[i]\n",
    "            #Fw_ = df['Fw'].iloc[i]\n",
    "    \n",
    "            #mu_ = int(include_emulsion(Fw_))\n",
    "                    \n",
    "            if Freq_ != Freq_start_:\n",
    "                Freq_start_ = Freq_\n",
    "                passport_power_table = create_power_from_production_table(NumStage_, Freq_start_, ESP_id_, mu_)\n",
    "                plot_pump(passport_power_table, well_name, Freq_start_, mu_)\n",
    "                #print('new pass because of another frequency')\n",
    "    \n",
    "            \n",
    "            \n",
    "            #Q_old = interpolated_power(df['Expected power'].iloc[i] # Значение дебита на прошлом шаге\n",
    "            N_passport = passport_power_table['Power'].values\n",
    "            Q_passport = passport_power_table['Production'].values\n",
    "            \n",
    "            Q_result = np.empty(0)\n",
    "            Q_for_interpolating = []\n",
    "            N_for_interpolating = []\n",
    "            n_new = df['Expected power'].iloc[i]\n",
    "            if low == True:\n",
    "                Q_old = df['Q mix pump cond'].iloc[i-1]\n",
    "            else:\n",
    "                Q_old = q_predicted_array[i-1]\n",
    "            \n",
    "            for j in range(1, len(N_passport)):\n",
    "                if (N_passport[j-1] <= n_new and N_passport[j] >= n_new) or (\n",
    "                    N_passport[j-1] >= n_new and N_passport[j] <= n_new):\n",
    "                    \n",
    "                    N_for_interpolating = [N_passport[j-1], N_passport[j]]\n",
    "                    Q_for_interpolating = [Q_passport[j-1], Q_passport[j]]\n",
    "                    interpolated_power = scipy.interpolate.interp1d(N_for_interpolating, Q_for_interpolating)\n",
    "                    Q_result = np.append(Q_result, interpolated_power(n_new))     \n",
    "            \n",
    "            print('Possible Q is', Q_result)\n",
    "            \n",
    "            if len(Q_result) != 0:\n",
    "                if Q_old == 0:\n",
    "                    #Если модель ушла в 0, то опираемся на последнее ненулевое значение\n",
    "                    Q_old = q_predicted_array[[i for i, e in enumerate(q_predicted_array) if e != 0][-1]]\n",
    "                Q = Q_result.flat[np.abs(Q_result - Q_old).argmin()] #Предсказываем дебит ближайший к последнему != 0\n",
    "                print('Selecting Q= ', Q)            \n",
    "            else:\n",
    "                Q = 0\n",
    "                print('Point out of model, Q = ', Q)\n",
    "                counter_off_bounds += 1\n",
    "            #interpolated_power = scipy.interpolate.interp1d(\n",
    "            #    passport_power_table['Power'].values, passport_power_table['Production'].values, \n",
    "            #    bounds_error=True)#\"extrapolate\")\n",
    "            \n",
    "            print('Expected power is {}'.format(df['Expected power'].iloc[i]))\n",
    "            try:\n",
    "                print('Real power is {}'.format(df['Active power'].iloc[i]))\n",
    "            except:\n",
    "                print('Real power is {}'.format(df['Active power 1H'].iloc[i]))\n",
    "            print('Frequency is {}'.format(Freq_))\n",
    "            \n",
    "            if df['Expected power'].iloc[i] < 10 or Freq_ < 10:\n",
    "                print('Pump is off!')\n",
    "                Q = 0\n",
    "            \n",
    "            #else:\n",
    "            #    if (df['Expected power'].iloc[i] < np.amax(passport_power_table['Power']) and \n",
    "            #                df['Expected power'].iloc[i] > np.amin(passport_power_table['Power'])):\n",
    "        #\n",
    "            #         Q = interpolated_power(df['Expected power'].iloc[i])\n",
    "            #    else:\n",
    "            #        print('Off pass, expected power is {}, max = {}, min = {}'.format(\n",
    "            #            df['Expected power'].iloc[i], np.amax(passport_power_table['Power']), \n",
    "            #            np.amin(passport_power_table['Power'])))\n",
    "            #        \n",
    "            #        #mu_temp = mu_ # Параметр для варьирования вязкости\n",
    "            #        counter_off_bounds += 1\n",
    "            #        while (df['Expected power'].iloc[i] > np.amax(passport_power_table['Power']) or \n",
    "            #                    df['Expected power'].iloc[i] < np.amin(passport_power_table['Power'])):\n",
    "        #\n",
    "            #            #plot_pump(passport_power_table, well_name, Freq_, mu_temp)\n",
    "            #            \n",
    "            #            if df['Expected power'].iloc[i] > np.amax(passport_power_table['Power']):\n",
    "            #                mu_temp += 0.5 \n",
    "            #                print('> ', mu_temp)\n",
    "            #                print('Excpected = {}, max = {}, min = {}'.format(df['Expected power'].iloc[i], \n",
    "            #                            np.amax(passport_power_table['Power']), np.amin(passport_power_table['Power'])))\n",
    "            #            elif df['Expected power'].iloc[i] < np.amin(passport_power_table['Power']):\n",
    "            #                mu_temp -= 0.5\n",
    "            #                print('< ', mu_temp)\n",
    "            #                print('Excpected = {}, max = {}, min = {}'.format(df['Expected power'].iloc[i], \n",
    "            #                                np.amax(passport_power_table['Power']), np.amin(passport_power_table['Power'])))\n",
    "            #            if mu_temp <= 0 or mu_temp > 5 * mu_:\n",
    "            #                \n",
    "            #                Q_off = q_predicted_array[-1] # Если не хватило коррекции по вязкости\n",
    "            #                print('mu_temp out of bounds, appending Q = ', Q_off)\n",
    "            #                break\n",
    "            #                \n",
    "            #            passport_power_table = create_power_from_production_table(NumStage_, Freq_start_, ESP_id_,\n",
    "            #                                                                      mu_temp, Mean_prod_)\n",
    "            #            #plot_pump(passport_power_table, well_name, Freq_, mu_temp)\n",
    "            #        \n",
    "        #\n",
    "            #        #mu_array.append(mu_temp)\n",
    "            #        ajusted_flag = True\n",
    "            #\n",
    "            #        print('Well {} adjusted, mu value is {}, mu from passport is {}, Freq is {} counter = {}'.format(\n",
    "            #            well_name, mu_temp, mu_, Freq_, counter_off_bounds))\n",
    "            #        #plot_pump(passport_power_table, well_name, Freq_, mu_temp)\n",
    "            #    \n",
    "    #\n",
    "            #    \n",
    "            #    interpolated_power = scipy.interpolate.interp1d(\n",
    "            #        passport_power_table['Power'].values, passport_power_table['Production'].values, \n",
    "            #        bounds_error=True)#\"extrapolate\")\n",
    "            #    if mu_temp <= 0 or mu_temp > 5 * mu_:\n",
    "            #        Q = Q_off\n",
    "            #    else:\n",
    "            #        Q = interpolated_power(df['Expected power'].iloc[i])\n",
    "            #    \n",
    "            #    mu_array.append(mu_temp)\n",
    "            \n",
    "            \n",
    "            #try:   \n",
    "            #    \n",
    "            #    interpolated_power = scipy.interpolate.interp1d(\n",
    "            #        passport_power_table['Power'].values, passport_power_table['Production'].values, \n",
    "            #        bounds_error=True)#\"extrapolate\")\n",
    "            #    Q = interpolated_power(df['Expected power'].iloc[i])\n",
    "            #            \n",
    "            #except:\n",
    "            #    if len(df) > 300: #чтобы выводить только для 3-х часового предсказания    \n",
    "            #        counter_off_bounds += 1\n",
    "            #    #print('Well {} is out of passport, adding average'.format(well_name))\n",
    "            #    temp = np.asarray(q_predicted_array)\n",
    "            #    mean = temp[temp > 0].mean() # При ошибке добавляем среднее на текущий момент значение (без -1)\n",
    "            #    if len(q_predicted_array) == 0:\n",
    "            #        mean = 0 \n",
    "            #    interpolated_power = scipy.interpolate.interp1d(\n",
    "            #        passport_power_table['Power'].values, passport_power_table['Production'].values, \n",
    "            #        bounds_error=False, fill_value = mean )\n",
    "            #    Q = interpolated_power(df['Expected power'].iloc[i])\n",
    "            #    print('Well {} is out of passport, expected power is {}, freq {}, mu {}'.format(well_name, \n",
    "            #                                                               df['Expected power'].iloc[i], Freq_, mu_))\n",
    "            \n",
    "        \n",
    "            \n",
    "            #print(i, ' ', Q, ' ',  df.iloc[i])\n",
    "            \n",
    "            #if Q > 0 and Q < 3 * max(q_mix_array):\n",
    "            #    q_predicted_array.append(Q)\n",
    "            #else:\n",
    "            #    try:\n",
    "            #        q_predicted_array.append(q_predicted_array[-1])\n",
    "            #    except:\n",
    "            #        q_predicted_array.append(0)\n",
    "            \n",
    "            # Все значения, не попавшие в диапазон, берем = 0\n",
    "            \n",
    "        Max_deriv_ = abs(max(passport_power_table['Derivative'].values)) # Максимальное зн-е производной N'q\n",
    "        dN_ = abs(df['dN expected'].iloc[i])\n",
    "        Max_dQ = abs(dN_ / Max_deriv_) # Максимально возможное изменение дебита\n",
    "\n",
    "        max_dQ_array.append(Max_dQ)\n",
    "\n",
    "        if i == 0:\n",
    "            Q = First_liq_point_ # Доверяем первому замеру\n",
    "            \n",
    "        q_predicted_array.append(Q)\n",
    "        \n",
    "        #!!!! \n",
    "        #Дебит на поверхности\n",
    "        \n",
    "        q_liq_surface.append(transform_to_surface_conditions(Q, i, df))\n",
    "        #!!!!\n",
    "        \n",
    "        #print('Q pump is {}'.format(Q))\n",
    "        #print('Expected power is ', df['Expected power'].iloc[i])\n",
    "        #print(passport_power_table)\n",
    "        \n",
    "        if ajusted_flag == True:\n",
    "            passport_power_table = create_power_from_production_table(NumStage_, Freq_start_, ESP_id_, mu_)\n",
    "        \n",
    "        print('Date is {}, Q predicted is {}, progress is {}%'.format(df.index[i], Q, np.round(i/len(df) * 100, 2)))\n",
    "    \n",
    "    if low == False: #чтобы выводить только для 3-х часового предсказания\n",
    "        print('Total number of points out of interpolation is {}'.format(counter_off_bounds))\n",
    "        #total_off_bounds = counter_off_bounds\n",
    "        \n",
    "    return (q_predicted_array, counter_off_bounds, mu_array, max_dQ_array, q_liq_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_for_optimization(Q, args):\n",
    "    \n",
    "    i = args[0] # Текущая точка в предсказанном массиве\n",
    "    df = args[1] # ДФ со всеми данными\n",
    "        \n",
    "    Q_true = args[2] #Реальный дебит модели в условиях насоса\n",
    "    Fw_ = df['Fw'].iloc[i]\n",
    "    #Temperature = df['Temperature on the surface'].iloc[i]\n",
    "    Pksep_atma_ = df['Давление на входе ЭЦН (ТМ)'].iloc[i]\n",
    "    TKsep_ = df['Температура двигателя ЭЦН (ТМ)'].iloc[i]\n",
    "    Rp_ = df['Газожидкостной фактор (рассчитанный)'].iloc[i]\n",
    "    \n",
    "    PVT_str = PVT_encode_string(gamma_gas_, gamma_oil_,gamma_wat_, Rsb_, Rp_, Pb_, Tres_, Bob_, mu_, PVT_corr_, \n",
    "                                KsepGasSep_, float(Pksep_atma_), float(TKsep_))\n",
    "    \n",
    "    Q_predicted = MF_q_mix_rc_m3day(float(Q), Fw_, float(Pksep_atma_), float(TKsep_), PVT_str)\n",
    "    error = math.sqrt((Q_predicted - Q_true)**2)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_surface_conditions(Q_pump, i, df):\n",
    "   \n",
    "    Q_start = 100 # Стартовая точка оптимизации\n",
    "        \n",
    "    minimized_result = minimize(get_error_for_optimization, Q_start, method = 'Nelder-Mead', \n",
    "                                args=[i, df, Q_pump]) #Запуск оптимизатора\n",
    "    #print('True value is {}, predicted is {}, error is {}'.format(Q_pump, minimized_result.x[0], \n",
    "    #                                                              np.abs(Q_pump - minimized_result.x[0])/Q_pump))\n",
    "    #print(minimized_result)\n",
    "    print('{}% completed'.format(np.round(i/len(df) * 100, 2)))\n",
    "    \n",
    "    return minimized_result.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_calculations(df_day, df_3h, well_name):\n",
    "    \n",
    "# Расчеты по МО, обучение и контроль ошибки на дневных данных, применяем обученные модели для 3 часовых \n",
    "\n",
    "    y = df_day['K degradation'].values\n",
    "    df_day.drop(columns=['K degradation'], inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_day, y, test_size=0.2, shuffle=True)\n",
    "    ten_pow = np.power(10.0, np.arange(-4, 2))\n",
    "    grid = {'alpha': ten_pow}\n",
    "    cv = KFold(n_splits = 5, shuffle = True)\n",
    "    clf_test = Ridge()\n",
    "    gs = GridSearchCV(clf_test, grid, cv=cv)\n",
    "    gs.fit(X_train,  y_train)\n",
    "    print(gs.best_estimator_)\n",
    "    \n",
    "    model = gs.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred_ridge_train = model.predict(X_train)\n",
    "    y_pred_ridge_test = model.predict(X_test)\n",
    "    \n",
    "        \n",
    "    train_r2_ridge = r2_score(y_train, y_pred_ridge_train)\n",
    "    test_r2_ridge = r2_score(y_test, y_pred_ridge_test)\n",
    "    \n",
    "    train_mae_ridge = mean_absolute_error(y_train, y_pred_ridge_train)\n",
    "    test_mae_ridge = mean_absolute_error(y_test, y_pred_ridge_test)\n",
    "    \n",
    "    y_res_ridge = model.predict(df_3h)\n",
    "\n",
    "    \n",
    "    model = RandomForestRegressor(max_depth=4, n_estimators=25, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_forest_train = model.predict(X_train)\n",
    "    y_pred_forest_test = model.predict(X_test)\n",
    "    \n",
    "    train_r2_forest = r2_score(y_train, y_pred_forest_train)\n",
    "    test_r2_forest = r2_score(y_test, y_pred_forest_test)\n",
    "  \n",
    "    train_mae_forest = mean_absolute_error(y_train, y_pred_forest_train)\n",
    "    test_mae_forest = mean_absolute_error(y_test, y_pred_forest_test)\n",
    "    \n",
    "    y_res_forest = model.predict(df_3h)\n",
    "    \n",
    "    path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                          'ГРАД', oilfield_, r'Результаты\\ML')\n",
    "    os.chdir(path)\n",
    "    \n",
    "    n_features = df_day.shape[1]\n",
    "    plt.figure(figsize = (25,12))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), df_day.columns)\n",
    "    plt.xlabel(\"Важность признака\")\n",
    "    plt.ylabel(\"Признак\")\n",
    "    plt.title('Скважина ' + well_name + ' Feature importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Скважина ' + well_name + ' Feature importances' + '.jpg')\n",
    "    plt.close();\n",
    "    \n",
    "    return {'Ridge' : y_res_ridge, 'Forest' : y_res_forest , 'train_r2_ridge' : train_r2_ridge , \n",
    "            'test_r2_ridge' : test_r2_ridge, 'train_mae_ridge' : train_mae_ridge, 'test_mae_ridge' : test_mae_ridge, \n",
    "            'train_r2_forest' : train_r2_forest, 'test_r2_forest' : test_r2_forest, \n",
    "            'train_mae_forest' : train_mae_forest, 'test_mae_forest' : test_mae_forest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisation(df_res, summary_df, df_vsp, well_name):#, df_ml_high , well_name):\n",
    "    if grad:\n",
    "        path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                              'ГРАД', oilfield_, r'Результаты\\Plots')\n",
    "    else:\n",
    "        path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                              'ГРАД', oilfield_, r'Результаты\\Plots\\SHTR')\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index,y=summary_df['Expected production'], mode='lines+markers', \n",
    "                   name=\"Expected production high freq (pump conditions)\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index,y=summary_df['Expected production on the surface'], mode='lines+markers', \n",
    "                   name=\"Expected production high freq (surface conditions)\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Expected production daily'], mode='lines+markers', \n",
    "                   name=\"Expected production daily (pump conditions)\")\n",
    "    )\n",
    "      \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Expected daily production on the surface'], mode='lines+markers', \n",
    "                   name=\"Expected production daily (surface conditions)\")\n",
    "    )\n",
    "     \n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Q mix pump cond'], marker={'size':10}, mode='lines+markers', \n",
    "                   name=\"Real production (pump conditions)\")\n",
    "    )\n",
    "   \n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=df_res.index, y=df_res['Дебит жидкости (ТМ)'], marker={'size':10}, mode='lines+markers', \n",
    "                   name=\"Real production (surface)\")\n",
    "    )\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=df_ml_high.index, y=df_ml_high['K ridge'], mode='lines+markers', name=\"K degradation predicted ridge\")\n",
    "    #)\n",
    "    #\n",
    "    #\n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=df_ml_high.index, y=df_ml_high['K forest'], mode='lines+markers', \n",
    "    #               name=\"K degradation predicted forest\")\n",
    "    #)\n",
    "   \n",
    "   \n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index,y=summary_df['K degradation'], mode='markers', name=\"K deg interpolated\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['K degradation'], mode='markers', name=\"K deg\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Газожидкостной фактор (рассчитанный)'], mode='lines+markers', \n",
    "                   name=\"Gas-liquid factor\")\n",
    "    )\n",
    "    \n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=summary_df.index,y=summary_df['Fw'], mode='markers', name=\"WC\")\n",
    "    #)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index, y=summary_df['Active power 1H'], mode='lines+markers', name=\"Active power 1H\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index, y=summary_df['Expected power'], mode='lines+markers', name=\"Expected power 1H\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=summary_df.index, y=summary_df['F ESP'], mode='lines+markers', name=\"ESP frequency\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Active power'], mode='lines+markers', name=\"Active power (low)\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['F ESP'], mode='lines+markers', name=\"ESP frequency (low)\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Давление на входе ЭЦН (ТМ)'], mode='lines+markers', name=\"Intake pressure\")\n",
    "    )    \n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_res.index, y=df_res['Давление линейное (ТМ)'], mode='lines+markers', name=\"Wellhead pressure\")\n",
    "    )\n",
    "    \n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=summary_df.index, y=summary_df['Давление линейное (ТМ)'], mode='lines+markers', name=\"Wellhead pressure\")\n",
    "    #)\n",
    "\n",
    "    \n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=summary_df.index, y=summary_df['mu emulsion'], mode='lines+markers', name=\"mu emulsion\")\n",
    "    #)\n",
    "    #\n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=df_res.index, y=df_res['mu emulsion'], mode='lines+markers', name=\"mu emulsion daily\")\n",
    "    #)\n",
    "    #\n",
    "    #fig.add_trace(\n",
    "    #    go.Scatter(x=df_ml_3h.index, y=df_ml_3h['Давление на входе ЭЦН (ТМ)'],\n",
    "    #                   mode='lines+markers', name=\"Pump intake pressure\")\n",
    "    #    )\n",
    "    \n",
    "    if len(df_vsp != 0):\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"rect\",\n",
    "                # x-reference is assigned to the x-values\n",
    "                xref=\"x\",\n",
    "                # y-reference is assigned to the plot paper [0,1]\n",
    "                yref=\"paper\",\n",
    "                x0=df_vsp['ДатаСтарта'].iloc[i],\n",
    "                y0=0,\n",
    "                x1=df_vsp['Дата_Окончания'].iloc[i],\n",
    "                y1=max(summary_df['Expected production']),\n",
    "                fillcolor=\"LightSalmon\",\n",
    "                opacity=0.3,\n",
    "                layer=\"below\",\n",
    "                line_width=0) for i in range(len(df_vsp))]\n",
    "            \n",
    "        fig.update_layout(\n",
    "            shapes=shapes\n",
    "            )\n",
    "    if grad:\n",
    "        fig.update_layout(\n",
    "            title_text= well_name + ' GRAD', template='plotly_white'\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(\n",
    "            title_text= well_name + ' SHTR', template='plotly_white'\n",
    "        )        \n",
    "                    \n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Дата\")\n",
    "    \n",
    "    #fig.update_yaxes(title_text=\"Production m3/day\")\n",
    "    if grad:\n",
    "        plotly.offline.plot(fig, filename = well_name + ' GRAD.html', auto_open=False)\n",
    "    else:\n",
    "        plotly.offline.plot(fig, filename = well_name + ' SHTR.html', auto_open=False)\n",
    "    \n",
    "    #fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pump(passport_power_table, well_name, Freq_, mu_):\n",
    "    # Функция постороения напорно-расходной хар-ки по мощности\n",
    "    path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                          'ГРАД', oilfield_, r'\\Результаты\\Pump passport')\n",
    "    os.chdir(path)\n",
    "    \n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(15,15))\n",
    "    plt.tight_layout()\n",
    "    ax.plot(passport_power_table['Production'], passport_power_table['Power'])\n",
    "    ax.set_xlabel(\"Production\",fontsize=14)\n",
    "    ax.set_ylabel(\"Power\",fontsize=14)\n",
    "    ax2=ax.twinx()\n",
    "    ax2.plot(passport_power_table['Production'], passport_power_table['Derivative'], color='red')\n",
    "    ax2.set_ylabel(\"Derivative\",fontsize=14)\n",
    "\n",
    "    plt.savefig(well_name + ', Freq = ' + str(Freq_) + ', mu = ' + str(mu_) + '.jpg', quality=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(validation_df, well_name):\n",
    "        # Функция постороения напорно-расходной хар-ки по мощности\n",
    "    path = os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                          'ГРАД', oilfield_, r'Результаты\\Error')\n",
    "    os.chdir(path)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.title(well_name + ' cross-plot')\n",
    "    plt.scatter(validation_df['Q mix pump cond'], validation_df['Expected production'])\n",
    "    plt.xlabel('Q mix pump cond')\n",
    "    plt.ylabel('Expected production')\n",
    "    plt.savefig(well_name + ' cross-plot' + '.jpg', quality=100)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_optimization(df):\n",
    "    Q_for_test = []\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        \n",
    "        Q = df['Expected daily production on the surface'].iloc[i]\n",
    "        Fw_ = df['Fw'].iloc[i]\n",
    "        Pksep_atma_ = df['Давление на входе ЭЦН (ТМ)'].iloc[i]\n",
    "        TKsep_ = df['Температура двигателя ЭЦН (ТМ)'].iloc[i]\n",
    "        Rp_ = df['Газожидкостной фактор (рассчитанный)'].iloc[i]\n",
    "        PVT_str = PVT_encode_string(gamma_gas_, gamma_oil_,gamma_wat_, Rsb_, Rp_, Pb_, Tres_, Bob_, mu_, PVT_corr_, \n",
    "                                    KsepGasSep_, float(Pksep_atma_), float(TKsep_))\n",
    "        \n",
    "        Q_for_test.append(MF_q_mix_rc_m3day(float(Q), Fw_, float(Pksep_atma_), float(TKsep_), PVT_str))\n",
    "    \n",
    "    df['Q test pump conditions'] = Q_for_test\n",
    "        \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index,y=df['Q test pump conditions'], mode='lines+markers', \n",
    "                   name=\"Test pump\")\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index,y=df['Expected production daily'], mode='lines+markers', \n",
    "                   name=\"Expected production high freq (pump conditions)\")\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text='Test', template='plotly_white'\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Дата\")\n",
    "    \n",
    "    \n",
    "    plotly.offline.plot(fig, filename = 'Optimization test.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение функций Unifloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xw.Book(os.path.join(cWorkFolder, r'VMetring\\unifloc 7_14\\UniflocVBA_7.xlam'))\n",
    "app = wb.app\n",
    "PVT_encode_string = app.macro('PVT_encode_string') \n",
    "MF_q_mix_rc_m3day = app.macro('MF_q_mix_rc_m3day')\n",
    "MF_gas_fraction_d = app.macro('MF_gas_fraction_d')\n",
    "ESP_power_W = app.macro('ESP_power_W')\n",
    "MF_p_pipe_atma = app.macro('MF_p_pipe_atma')\n",
    "ESP_id_by_rate = app.macro('ESP_id_by_rate')\n",
    "ESP_name = app.macro('ESP_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1982']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e569682de6ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mBSI\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mall_data_high\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_averaged_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwell_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data_high\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Дебит жидкости (ТМ)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-149268c4d693>\u001b[0m in \u001b[0;36mget_averaged_data\u001b[1;34m(low, well_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwell_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_both\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwell_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-afc8a3723593>\u001b[0m in \u001b[0;36mget_data_both\u001b[1;34m(low, well_name, filename)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8-sig\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "for oilfield_ in oilfields:\n",
    "    \n",
    "    if oilfield_ == 'Суторминское':\n",
    "        gamma_oil_ = 0.808\n",
    "        gamma_wat_ = 1\n",
    "        gamma_gas_ = 0.754\n",
    "        Rsb_ = 15.6\n",
    "        Rp_ = 186\n",
    "        Pb_ = 138.7\n",
    "        Tres_ = 76\n",
    "        Bob_ = 1.486\n",
    "        mu_ = 2.846 # Вязкость нефти, из PVT\n",
    "    elif oilfield_ == 'Вынгаяхинское':\n",
    "        gamma_oil_ = 0.82\n",
    "        gamma_wat_ = 1\n",
    "        gamma_gas_ = 0.796\n",
    "        Rsb_ = 15.6\n",
    "        Rp_ = 124\n",
    "        Pb_ = 139\n",
    "        Tres_ = 89\n",
    "        Bob_ = 1.278\n",
    "        mu_ = 7.76 # Вязкость нефти, из PVT\n",
    "    elif oilfield_ == 'Восточно-Пякутинское':\n",
    "        gamma_oil_ = 0.846\n",
    "        gamma_wat_ = 1\n",
    "        gamma_gas_ = 0.712\n",
    "        Rsb_ = 15.6\n",
    "        Rp_ = 73\n",
    "        Pb_ = 122.4\n",
    "        Tres_ = 85\n",
    "        Bob_ = 1.168\n",
    "        mu_ = 12.96 # Вязкость нефти, из PVT\n",
    "        \n",
    "        # Список скважин\n",
    "        \n",
    "    os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                          'ГРАД', oilfield_, 'Скважины'))\n",
    "    \n",
    "    filenames = []\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        filenames.append(file[:-4])\n",
    "    print(filenames)\n",
    "    \n",
    "    #filenames = ['2355']\n",
    "    \n",
    "    N = 1 # Параметр для проверки качества модели (выкижываем каждую N-ю точку и считаем ошибку)\n",
    "    # ДФ для записи всех логов и результатов\n",
    "    log_df = pd.DataFrame(index = [filenames], columns=['ESP name real', 'ESP name used', 'ESP id', \n",
    "                                                        'Average production', 'MAE score', 'Average error, %', \n",
    "                                                        'Maximum absolute error', 'Average production surface', \n",
    "                                                        'MAE score surface', 'Average error surface, %', \n",
    "                                                        'Maximum absolute error surface', 'MAE score surface restoring', \n",
    "                                                        'Maximum absolute error surface restoring',\n",
    "                                                        'Average error because incorrect passport, %', \n",
    "                                                        'Total № of points off passport bounds', 'R2 score',\n",
    "                                                        'R2 test score ridge', 'R2 train score ridge', \n",
    "                                                        'MAE test score ridge', 'MAE train score ridge', \n",
    "                                                        'Average MAE test score ridge, %', \n",
    "                                                        'Average MAE train score ridge, %', 'R2 test score forest',\n",
    "                                                        'R2 train score forest', 'MAE test score forest', \n",
    "                                                        'MAE train score forest', 'Average MAE test score forest, %', \n",
    "                                                        'Average MAE train score forest, %'])\n",
    "    \n",
    "    for names in zip(range(len(filenames)), filenames):\n",
    "    \n",
    "        well_name = names[1]\n",
    "        \n",
    "        if well_name in ['6011', '6013', '1976', '3026', '337', '2338', '2355', '3900', '3922']:\n",
    "            grad = False\n",
    "        else:\n",
    "            grad = True\n",
    "        \n",
    "        tube_and_pump = get_tube_and_pump_characteristics(well_name, oilfield_)\n",
    "        Hpump_ = tube_and_pump['Hpump_']\n",
    "        NumStage_ = tube_and_pump['NumStage_']\n",
    "        Dcas_ = tube_and_pump['Dcas_']\n",
    "        #Dtub_ = tube_and_pump['Dtub_']\n",
    "        Dtub_ = 79 #нехорошо\n",
    "        ESP_id_ = int(tube_and_pump['ESP_id_'])\n",
    "        ESP_name_ = tube_and_pump['ESP_name_']\n",
    "        ESP_name_unifloc_ = tube_and_pump['ESP_name_unifloc_']\n",
    "        \n",
    "        # По ШТР\n",
    "        if grad == False and BSI == False:\n",
    "            all_data = get_averaged_data(True, well_name)\n",
    "            all_data_high = get_averaged_data(False, well_name)\n",
    "            \n",
    "        # По БСИ\n",
    "        elif grad and BSI:\n",
    "            all_data_high = get_averaged_data(False, well_name).resample('60S').mean()\n",
    "            all_data = get_averaged_data(True, well_name)\n",
    "            \n",
    "        elif grad and BSI == False:\n",
    "            all_data_high = get_averaged_data(False, well_name)\n",
    "            all_data = all_data_high.dropna(subset=['Дебит жидкости (ТМ)'])\n",
    "        else:\n",
    "            print('ГЫГ')\n",
    "            all_data = get_averaged_data(True, well_name)\n",
    "            all_data.dropna(subset=['Дебит жидкости (ТМ)'], inplace=True)\n",
    "        \n",
    "        #all_data.dropna(subset=['Дебит жидкости (ТМ)'], inplace=True)\n",
    "        #all_data['Активная мощность (ТМ)'].interpolate(limit_direction='both', inplace=True)\n",
    "        all_data['Газожидкостной фактор (рассчитанный)'].interpolate(limit_direction='both', inplace=True) \n",
    "        all_data['Частота вращения (ТМ)'].interpolate(limit_direction='both', inplace=True) \n",
    "        all_data['Температура двигателя ЭЦН (ТМ)'].interpolate(limit_direction='both', inplace=True) \n",
    "        \n",
    "        df_vsp = get_vsp(oilfield_, well_name)\n",
    "            \n",
    "        if all_data.index[0] < all_data_high.index[0]:\n",
    "            all_data = all_data.truncate(before = all_data_high.index[0])\n",
    "            all_data_high = all_data_high.truncate(before = all_data.index[0])\n",
    "            \n",
    "        else:\n",
    "            all_data_high = all_data_high.truncate(before = all_data.index[0])\n",
    "            all_data = all_data.truncate(before = all_data_high.index[0])\n",
    "        \n",
    "        if all_data.index[-1] > all_data_high.index[-1]:    \n",
    "            all_data = all_data.truncate(after = all_data_high.index[-1])\n",
    "            all_data_high = all_data_high.truncate(after = all_data.index[-1])\n",
    "        \n",
    "        else:\n",
    "            all_data_high = all_data_high.truncate(after = all_data.index[-1])\n",
    "            all_data = all_data.truncate(after = all_data_high.index[-1])\n",
    "\n",
    "        #if df_vsp.index[0] < all_data.index[0]:\n",
    "        #    df_vsp = df_vsp.truncate(before = all_data.index[0])\n",
    "        #if df_vsp.index[-1] > all_data.index[-1]:\n",
    "        #    df_vsp = df_vsp.truncate(after = all_data.index[-1])\n",
    "        \n",
    "            \n",
    "        print('Input data begins at {}, {}, ends at {}, {}'.format(all_data_high.index[0], all_data.index[0], \n",
    "                                                       all_data_high.index[-1], all_data.index[-1]))\n",
    "        # Проверка на Мпа/атм\n",
    "        print('Average pressure, ', all_data['Давление линейное (ТМ)'].dropna().mean())\n",
    "        if all_data['Давление линейное (ТМ)'].dropna().mean() < 3:\n",
    "            all_data['Давление линейное (ТМ)'] = all_data['Давление линейное (ТМ)'] * 9.869\n",
    "            if BSI == False:\n",
    "                all_data_high['Давление линейное (ТМ)'] = all_data_high['Давление линейное (ТМ)'] * 9.869\n",
    "        \n",
    "        if grad == False and BSI == False:\n",
    "            active_power_1H = all_data_high[['Активная мощность (ТМ)']]\n",
    "            f_esp_1H = all_data_high[['Частота вращения (ТМ)']]\n",
    "            p_lin_1H = all_data_high[['Давление линейное (ТМ)']]\n",
    "            \n",
    "        if grad and BSI == False: \n",
    "            active_power_1H = all_data_high[['Активная мощность (ТМ)']]\n",
    "            f_esp_1H = all_data_high[['Частота вращения (ТМ)']]\n",
    "            p_lin_1H = all_data_high[['Давление линейное (ТМ)']]        \n",
    "            tKsep_1H = all_data_high[['Температура двигателя ЭЦН (ТМ)']]\n",
    "            pksep_atma_1H = all_data_high[['Давление на входе ЭЦН (ТМ)']]\n",
    "            rp_1H = all_data_high[['Газожидкостной фактор (рассчитанный)']]\n",
    "            wc_1h = all_data_high[['Обводненность (ТМ)']]\n",
    "        \n",
    "        if grad and BSI:\n",
    "            active_power_1H = all_data_high[['Активная мощность (ТМ)']]#.resample('60S').mean()\n",
    "            f_esp_1H = all_data_high[['Частота вращения (ТМ)']]#.resample('60S').mean()\n",
    "            tKsep_1H = all_data_high[['Температура двигателя ЭЦН (ТМ)']]#.resample('60S').mean()\n",
    "            pksep_atma_1H = all_data_high[['Давление на входе ЭЦН (ТМ)']]#.resample('60S').mean()\n",
    "\n",
    "   \n",
    "        \n",
    "        f_esp_1H.rename(columns = {'Частота вращения (ТМ)' : 'F ESP'}, inplace=True)\n",
    "        inclinometry = get_inclinometry(well_name)\n",
    "        \n",
    "        log_df.loc[well_name]['ESP name real'] = ESP_name_\n",
    "        log_df.loc[well_name]['ESP name used'] = ESP_name_unifloc_\n",
    "        log_df.loc[well_name]['ESP id'] = str(ESP_id_)\n",
    "        \n",
    "        pressure_at_the_discharge = []\n",
    "        k_deg = [] # Массив суточных коэффициентов деградации\n",
    "        \n",
    "        q_mix_array = [] # Массив суточных дебитов в условиях насоса\n",
    "        \n",
    "       \n",
    "        passp_pow = [] # Массив паспортных мощностей раз в сутки\n",
    "        \n",
    "      \n",
    "          \n",
    "        df_res = pd.DataFrame(index = all_data.index, columns = ['Q mix pump cond', 'K degradation'])\n",
    "        Freq_start_ = all_data['Частота вращения (ТМ)'].iloc[0] # частота ЭЦН в первый день\n",
    "        \n",
    "        for i in range(len(all_data)):\n",
    "            \n",
    "            Rp_ = all_data['Газожидкостной фактор (рассчитанный)'].iloc[i]\n",
    "            Pksep_atma_ = all_data['Давление на входе ЭЦН (ТМ)'].iloc[i]\n",
    "            Qliq_ = all_data['Дебит жидкости (ТМ)'].iloc[i]\n",
    "            Fw_ = all_data['Обводненность (ТМ)'].iloc[i]\n",
    "            Fw_mean_ = all_data[['Обводненность (ТМ)']].mean()#[0]\n",
    "            Active_pow_ = all_data['Активная мощность (ТМ)'].iloc[i]\n",
    "                           \n",
    "            \n",
    "            #mu_ = int(include_emulsion(Fw_mean_))\n",
    "            #mu_ = int(include_emulsion(Fw_))\n",
    "                    \n",
    "            Pintake_ = Pksep_atma_    \n",
    "            Plin_ = all_data['Давление линейное (ТМ)'].iloc[i]\n",
    "            Freq_ = all_data['Частота вращения (ТМ)'].iloc[i]\n",
    "            TKsep_ = all_data['Температура двигателя ЭЦН (ТМ)'].iloc[i]\n",
    "            Tintake_ = TKsep_\n",
    "\n",
    "            \n",
    "            PVT_str = PVT_encode_string(gamma_gas_, gamma_oil_,gamma_wat_, Rsb_, Rp_, Pb_, Tres_, Bob_, mu_, PVT_corr_, \n",
    "                                        KsepGasSep_, float(Pksep_atma_), float(TKsep_))\n",
    "            pressure_full_temp = [Plin_] # Распределение давления по стволу (свое в каждый день)\n",
    "            j = 1\n",
    "            while inclinometry['MD'].iloc[j] < Hpump_:\n",
    "                Length_ = inclinometry['MD'].iloc[j] - inclinometry['MD'].iloc[j-1]\n",
    "                Pcalc_ = pressure_full_temp[j-1]\n",
    "                Calc_along_flow_ = 0\n",
    "                Theta_deg = inclinometry['Inc'].iloc[j]\n",
    "                Hydr_corr_ = 0\n",
    "                Tcalc_ = Tres_\n",
    "                Tother_ = Tcalc_\n",
    "                \n",
    "                pressure_full_temp.append(MF_p_pipe_atma(Qliq_, Fw_, int(Length_), Pcalc_, Calc_along_flow_, \n",
    "                                                         PVT_str, Theta_deg, Dtub_, Hydr_corr_, Tcalc_, Tother_)[0])\n",
    "                \n",
    "                j += 1\n",
    "        \n",
    "            pressure_at_the_discharge.append(pressure_full_temp[-1]) # Массив давлений на выкиде насоса на каждый день\n",
    "            \n",
    "            Q_mix_intake_ = MF_q_mix_rc_m3day(Qliq_, Fw_, float(Pintake_), float(Tintake_), PVT_str)\n",
    "            Q_mix_discharge_ = MF_q_mix_rc_m3day(Qliq_, Fw_, pressure_at_the_discharge[-1], \n",
    "                                                 float(Tintake_), PVT_str)\n",
    "            Q_mix_ = (Q_mix_intake_ + Q_mix_discharge_) / 2 # Дебит ГЖС в условиях насоса\n",
    "            \n",
    "            \n",
    "            q_mix_array.append(Q_mix_)\n",
    "            \n",
    "            Passport_pow_ = ESP_power_W(Q_mix_, NumStage_, Freq_, ESP_id_, mu_)/1000 # Вт -> КВт, мощность модели ЭЦН\n",
    "            k_deg.append(Active_pow_/Passport_pow_)\n",
    "            #freq.append(Freq_)\n",
    "            passp_pow.append(Passport_pow_)\n",
    "        \n",
    "        \n",
    "        df_res['Q mix pump cond'] = q_mix_array\n",
    "        df_res['K degradation'] = k_deg\n",
    "        df_res['F ESP'] = all_data['Частота вращения (ТМ)']\n",
    "        df_res['Expected power'] = passp_pow\n",
    "        df_res['Active power'] = all_data['Активная мощность (ТМ)']\n",
    "        df_res['dN expected'] =  df_res['Expected power'].diff() # Изменение активной мощности в 8 часовых данных\n",
    "        df_res['dN expected'].fillna(method='backfill', inplace=True)\n",
    "        df_res['Газожидкостной фактор (рассчитанный)'] = all_data['Газожидкостной фактор (рассчитанный)']\n",
    "        \n",
    "    \n",
    "        df_res['Fw'] = all_data['Обводненность (ТМ)']\n",
    "        df_res['Давление на входе ЭЦН (ТМ)'] = all_data['Давление на входе ЭЦН (ТМ)']\n",
    "        df_res['Температура двигателя ЭЦН (ТМ)'] = all_data['Температура двигателя ЭЦН (ТМ)']\n",
    "        df_res['Дебит жидкости (ТМ)'] =  all_data['Дебит жидкости (ТМ)']\n",
    "        df_res['Давление линейное (ТМ)'] = all_data['Давление линейное (ТМ)'] \n",
    "       \n",
    "        #Данные за каждые сутки без ошибок в вычислениях\n",
    "        df_res.drop(df_res[df_res['Q mix pump cond']==-1].index, inplace=True) \n",
    "        #df_res[['F ESP']] = df_res[['F ESP']].interpolate() # На случай пропусков в суточных данных\n",
    "        df_res.dropna(inplace=True) # На случай пропусков в суточных данных\n",
    "         \n",
    "        Mean_prod_ = df_res['Q mix pump cond'].mean() # Средний дебит по скважине (после выброса -1!)\n",
    "        \n",
    "            \n",
    "        # Производим расчеты с выбросом некоторых дней с целью контроля ошибки! \n",
    "        if grad and BSI == False:\n",
    "            summary_df = get_data_for_validation(N, df_res, active_power_1H, f_esp_1H, tKsep_1H, wc_1h, \n",
    "                                                     rp_1H, pksep_atma_1H, p_lin_1H)[0]\n",
    "        elif grad and BSI:\n",
    "            summary_df = get_data_for_validation(N, df_res, active_power_1H, f_esp_1H, tKsep_1H, pksep_atma_1H)[0]    \n",
    "        else:\n",
    "            summary_df = get_data_for_validation(N, df_res, active_power_1H, f_esp_1H, p_lin_1H)[0]\n",
    "            \n",
    "        # = pd.concat([active_power_3H, interpolated_k_deg_3H, resampled_f_esp, resampled_fw], axis=1).reindex()\n",
    "        \n",
    "        # Подумать, стоит ли так делать\n",
    "        # Пропуски мощности инт-ем\n",
    "        #summary_df['Активная мощность (ТМ)'] = summary_df['Активная мощность (ТМ)'].interpolate() \n",
    "\n",
    "        summary_df.dropna(inplace=True)\n",
    "       \n",
    "           \n",
    "        # Делаем ДФ для МО с частотой 1 час\n",
    "        \n",
    "        #summary_df_ml = get_averaged_data(False, well_name)\n",
    "        #\n",
    "        #resampled_k_deg = df_res[['K degradation']].resample('1H') # Для МО\n",
    "        #resampled_f_esp = df_res[['F ESP']].resample('1H').interpolate()\n",
    "        #interpolated_k_deg_1H = resampled_k_deg.interpolate()\n",
    "        #\n",
    "        #summary_df_ml = pd.concat([summary_df_ml, interpolated_k_deg_1H, resampled_f_esp], axis=1).reindex()\n",
    "        \n",
    "        # Ожидаемая активная мощность\n",
    "        summary_df['Expected power'] = summary_df['Активная мощность (ТМ)'] / summary_df['K degradation']\n",
    "        \n",
    "        summary_df['dN expected'] = summary_df['Expected power'].diff() # Изменение активной мощности\n",
    "        summary_df['dN expected'].fillna(method='backfill', inplace=True)\n",
    "        \n",
    "        summary_df.rename(columns={'Активная мощность (ТМ)':'Active power 1H', 'Обводненность (ТМ)' : 'Fw'}, inplace=True)\n",
    "    \n",
    "         #Приводим к одному моменту начала\n",
    "        \n",
    "        if df_res.index[0] < summary_df.index[0]:\n",
    "            df_res = df_res.truncate(before = summary_df.index[0])\n",
    "            summary_df = summary_df.truncate(before = df_res.index[0])\n",
    "            \n",
    "        else:\n",
    "            summary_df = summary_df.truncate(before = df_res.index[0])\n",
    "            df_res = df_res.truncate(before = summary_df.index[0])\n",
    "            \n",
    "        if df_res.index[-1] > summary_df.index[-1]:    \n",
    "            df_res = df_res.truncate(after = summary_df.index[-1])\n",
    "            summary_df = summary_df.truncate(after = df_res.index[-1])\n",
    "        \n",
    "        else:\n",
    "            summary_df = summary_df.truncate(after = df_res.index[-1])\n",
    "            df_res = df_res.truncate(after = summary_df.index[-1])\n",
    "        \n",
    "        print('Calculations data begins at {}, {}, ends at {}, {}'.format(summary_df.index[0], df_res.index[0], \n",
    "                                                       summary_df.index[-1], df_res.index[-1]))\n",
    "        \n",
    "        #summary_df_ml['Expected power'] = summary_df['Expected power']\n",
    "        \n",
    "        passport_power_table = create_power_from_production_table(NumStage_, Freq_start_, ESP_id_, mu_)\n",
    "        \n",
    "        plot_pump(passport_power_table, well_name, Freq_start_, mu_)\n",
    "        \n",
    "        First_liq_point_ = df_res['Q mix pump cond'][0] # Доверяем первому замеру, берем его за стартовую точку\n",
    "        \n",
    "        expected_q_8h = get_Q_prediction(True, df_res, First_liq_point_, NumStage_, Freq_start_, ESP_id_, mu_, \n",
    "                                         passport_power_table, Fw_mean_, well_name)\n",
    "        expected_q_1h = get_Q_prediction(False, summary_df, First_liq_point_, NumStage_, Freq_start_, ESP_id_, mu_, \n",
    "                                         passport_power_table, Fw_mean_, well_name)\n",
    "        \n",
    "        summary_df['Expected production'] = expected_q_1h[0]\n",
    "        \n",
    "        summary_df['Expected production on the surface'] =  expected_q_1h[4]\n",
    "        \n",
    "        #summary_df['mu emulsion'] = expected_q_1h[2]\n",
    "        summary_df['Max allowed dQ'] = expected_q_1h[3]\n",
    "        summary_df['Real dQ'] = summary_df['Expected production'].diff()\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        df_res['Expected production daily'] = expected_q_8h[0]\n",
    "        \n",
    "        df_res['Expected daily production on the surface'] =  expected_q_8h[4]\n",
    "        \n",
    "        #df_res['mu emulsion'] = expected_q_8h[2]\n",
    "        df_res['Max allowed dQ'] = expected_q_8h[3]\n",
    "        df_res['Real dQ'] = df_res['Expected production daily'].diff()\n",
    "        \n",
    "        # Ошибка при восстановлении дебита на поверхности почти константа, делаем смещение расчетов (костыль, колхоз)\n",
    "        \n",
    "        Mean_error_surface = (df_res['Дебит жидкости (ТМ)'] - df_res['Expected daily production on the surface']).mean()\n",
    "        df_res['Expected daily production on the surface'] += Mean_error_surface\n",
    "        summary_df['Expected production on the surface'] += Mean_error_surface\n",
    "        \n",
    "        #summary_df_ml['Q mix pump cond'] = summary_df['Expected production'] #??????????????????????????????????????\n",
    "        \n",
    "        # ДФ для валидации работы алгоритма (выкинут каждый N-й день)\n",
    "        # Ресемпл с выкинутыми данными по их ключу-индексу\n",
    "        if grad and BSI == False:\n",
    "            validation_df = pd.concat([get_data_for_validation(\n",
    "                N, df_res, active_power_1H, f_esp_1H, tKsep_1H, wc_1h, rp_1H, pksep_atma_1H, \n",
    "                    p_lin_1H)[1], summary_df], axis=1).reindex()\n",
    "        elif grad and BSI:\n",
    "            validation_df = pd.concat([get_data_for_validation(\n",
    "                N, df_res, active_power_1H, f_esp_1H, tKsep_1H, pksep_atma_1H)[1], summary_df], axis=1).reindex()\n",
    "        else: \n",
    "            validation_df = pd.concat([get_data_for_validation(\n",
    "                N, df_res, active_power_1H, f_esp_1H, p_lin_1H)[1], summary_df], axis=1).reindex()\n",
    "        \n",
    "        \n",
    "        validation_df = validation_df[['Q mix pump cond', 'Expected production', 'Дебит жидкости (ТМ)', \n",
    "                                        'Expected daily production on the surface', 'Expected production on the surface']]\n",
    "        validation_df.dropna(inplace=True)    \n",
    "        \n",
    "        log_df.loc[well_name]['Average production'] = str(np.round(Mean_prod_, 2))\n",
    "        \n",
    "        log_df.loc[well_name]['MAE score'] = str(mean_absolute_error(validation_df['Q mix pump cond'], \n",
    "                                                                 validation_df['Expected production']).round(2))\n",
    "        \n",
    "        log_df.loc[well_name]['Maximum absolute error'] = str(max_error(validation_df['Q mix pump cond'], \n",
    "                                                                 validation_df['Expected production']).round(2))\n",
    "            \n",
    "        log_df.loc[well_name]['Average error, %'] = str((mean_absolute_error(\n",
    "            validation_df['Q mix pump cond'], validation_df['Expected production']) / np.round(Mean_prod_, 2) * 100))\n",
    "        \n",
    "        log_df.loc[well_name]['Average production surface'] = str(np.round(np.mean(df_res['Дебит жидкости (ТМ)']), 2))\n",
    "        \n",
    "        log_df.loc[well_name]['MAE score surface'] = str(mean_absolute_error(\n",
    "            validation_df['Дебит жидкости (ТМ)'], validation_df['Expected production on the surface']).round(2))\n",
    "        \n",
    "        log_df.loc[well_name]['Maximum absolute error surface'] = str(max_error(\n",
    "            validation_df['Дебит жидкости (ТМ)'], validation_df['Expected production on the surface']).round(2))\n",
    "           \n",
    "        log_df.loc[well_name]['Average error surface, %' ] = str((mean_absolute_error(\n",
    "            validation_df['Дебит жидкости (ТМ)'], validation_df['Expected production on the surface']) / np.round(\n",
    "                                                                   np.mean(df_res['Дебит жидкости (ТМ)']), 2) * 100))\n",
    "        \n",
    "        \n",
    "        log_df.loc[well_name]['MAE score surface restoring'] = str(mean_absolute_error(\n",
    "            validation_df['Дебит жидкости (ТМ)'], validation_df['Expected daily production on the surface']).round(2))\n",
    "        \n",
    "        log_df.loc[well_name]['Maximum absolute error surface restoring'] = str(max_error(\n",
    "            validation_df['Дебит жидкости (ТМ)'], validation_df['Expected daily production on the surface']).round(2))                        \n",
    "        \n",
    "        #log_df.loc[well_name]['R2 score'] = str(r2_score(validation_df['Q mix pump cond'], \n",
    "        #                                             validation_df['Expected production']).round(2))\n",
    "        \n",
    "        \n",
    "        log_df.loc[well_name]['Average error because incorrect passport, %'] = str((mean_absolute_error(\n",
    "            df_res['Q mix pump cond'], df_res['Expected production daily']) / np.round(Mean_prod_, 2) * 100))\n",
    "        \n",
    "        log_df.loc[well_name]['Total № of points off passport bounds'] = str(expected_q_1h[1])\n",
    "        \n",
    "        plot_error(validation_df, well_name)\n",
    "        \n",
    "        #df_ml_low = get_data_for_ml(df_res, all_data)\n",
    "        #df_ml_high = get_data_for_ml(summary_df, all_data_high)\n",
    "        #\n",
    "        #df_ml_high.rename(columns = {'Active power 1H':'Active power'}, inplace=True)\n",
    "        #col_to_drop = ['Газожидкостной фактор (рассчитанный)', 'Дебит газа (ТМ)', 'Дебит жидкости (ТМ)', 'Дебит нефти (ТМ)',\n",
    "        #              'Газовый фактор (рассчитанный)', 'Электроэнергия со счетчика (ТМ)',\n",
    "        #              'Дисбаланс напряжений, %', 'Fw', 'Active power', 'F ESP', 'Expected power']\n",
    "        #if well_name == '1982':\n",
    "        #    col_to_drop = col_to_drop + ['Сопротивление изоляции (ТМ)']\n",
    "        #    \n",
    "        #df_ml_low.drop(columns=col_to_drop + ['Expected production daily', 'Q mix pump cond'], inplace=True)\n",
    "        #\n",
    "        #\n",
    "        #df_ml_high.drop(columns=col_to_drop + ['Expected production'], inplace=True)\n",
    "        #\n",
    "        #df_ml_high.dropna(how='all', inplace=True)\n",
    "        #df_ml_low.dropna(how='all', inplace=True)\n",
    "        #df_ml_high.dropna(inplace=True)\n",
    "        #df_ml_low.dropna(inplace=True)\n",
    "        #\n",
    "        #df_ml_high.drop(columns = ['K degradation'], inplace=True)\n",
    "        #\n",
    "        ### Ml calcls\n",
    "   #\n",
    "        #ml_result = ml_calculations(df_ml_low, df_ml_high, well_name)\n",
    "#\n",
    "        #df_ml_high['K ridge'] = ml_result['Ridge']\n",
    "        #df_ml_high['K forest'] = ml_result['Forest']\n",
    "        #\n",
    "        #log_df.loc[well_name]['R2 test score ridge'] = str(ml_result['test_r2_ridge'].round(2))\n",
    "        #log_df.loc[well_name]['R2 train score ridge'] = str(ml_result['train_r2_ridge'].round(2))\n",
    "        #log_df.loc[well_name]['MAE test score ridge'] = str(ml_result['test_mae_ridge'].round(2))\n",
    "        #log_df.loc[well_name]['MAE train score ridge'] = str(ml_result['train_mae_ridge'].round(2))\n",
    "        #\n",
    "        #log_df.loc[well_name]['Average MAE test score ridge, %'] = str((ml_result[\n",
    "        #                                                            'test_mae_ridge'] /np.round(Mean_prod_, 2) * 100))\n",
    "        #log_df.loc[well_name]['Average MAE train score ridge, %'] = str((ml_result[\n",
    "        #                                                                'train_mae_ridge'] /np.round(Mean_prod_, 2) * 100))\n",
    "        #\n",
    "        #log_df.loc[well_name]['R2 test score forest'] = str(ml_result['test_r2_forest'].round(2))\n",
    "        #log_df.loc[well_name]['R2 train score forest'] = str(ml_result['train_r2_forest'].round(2))\n",
    "        #log_df.loc[well_name]['MAE test score forest'] = str(ml_result['test_mae_forest'].round(2))\n",
    "        #log_df.loc[well_name]['MAE train score forest'] = str(ml_result['train_mae_forest'].round(2))\n",
    "        #\n",
    "        #log_df.loc[well_name]['Average MAE test score forest, %'] = str(\n",
    "        #    (ml_result['test_mae_forest'] /np.round(Mean_prod_, 2) * 100))\n",
    "        #log_df.loc[well_name]['Average MAE train score forest, %'] = str(\n",
    "        #    (ml_result['train_mae_forest'] / np.round(Mean_prod_, 2) * 100))\n",
    "        #   \n",
    "        os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                              'ГРАД', oilfield_, r'Результаты\\Calc results'))\n",
    "        \n",
    "        summary_df.to_csv(well_name + ' summary 1H.csv')\n",
    "        validation_df.to_csv(well_name + ' validation.csv')\n",
    "        df_res.to_csv(well_name + ' summary 8h.csv')\n",
    "        os.chdir(os.path.join(cWorkFolder, r'Данные для виртуальной расходометрии\\Ноябрьск\\информация для виртуального расходомера', \n",
    "                              'ГРАД', oilfield_, r'Результаты'))\n",
    "        log_df.to_csv('log.csv', encoding = 'windows 1251')\n",
    "        visualisation(df_res, summary_df, df_vsp, well_name) #df_ml_3h, well_name)\n",
    "        \n",
    "        #print(statistics.variance(df_res['Expected daily production on the surface'] - df_res['Дебит жидкости (ТМ)']))\n",
    "        \n",
    "        print('well № {} calculated, total progress is {} %'.format(str(names[1]),\n",
    "            (int(names[0])+1)/len(filenames) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.array([25, 15, 14, 12, 11, 10, 11, 12, 14, 15, 20, 25, 30, 35, 37, 38, 39, 40, 39, 35,24])\n",
    "Q = range(1, len(N)+1, 1)\n",
    "Q_result = np.empty(0)\n",
    "Q_for_interpolating = []\n",
    "N_for_interpolating = []\n",
    "plt.plot(N, Q)\n",
    "n_new = 24.8\n",
    "vert = [n_new]*len(Q)\n",
    "plt.plot(vert,Q)\n",
    "Q_point = 10\n",
    "for i in range(1, len(N)):\n",
    "    if (N[i-1] <= n_new and N[i] >= n_new) or (N[i-1] >= n_new and N[i] <= n_new):\n",
    "        print(N[i-1], N[i])\n",
    "        N_for_interpolating = [N[i-1], N[i]]\n",
    "        Q_for_interpolating = [Q[i-1], Q[i]]\n",
    "        Inter = scipy.interpolate.interp1d(N_for_interpolating, Q_for_interpolating)\n",
    "        Q_result = np.append(Q_result, Inter(n_new))\n",
    "                \n",
    "        print('Possible Q is', Q_result)\n",
    "res = Q_result.flat[np.abs(Q_result - Q_point).argmin()]\n",
    "print('Selecting Q= ', res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
